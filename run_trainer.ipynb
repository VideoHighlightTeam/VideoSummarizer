{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Summarizer 모델 학습/평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r'E:\\Work\\YasuoNet\\data\\dataset14_sl3_vsr2_vw64_vh64_asr22050_mfcc'\n",
    "ckpt_dir = 'checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "\n",
    "data_loader = DataLoader(dataset_dir, x_includes=['video', 'audio'])\n",
    "\n",
    "data_config = data_loader.get_metadata()['config']\n",
    "input_shape_dict = data_loader.get_metadata()['data_shape']\n",
    "class_counts = data_loader.all_segment_df['label'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "class_weights = (1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv3D, Conv2D, Input, MaxPool3D, MaxPool2D, Flatten, Activation, concatenate\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model(input_shape_dict):\n",
    "    video_input_shape = input_shape_dict['video']\n",
    "    audio_input_shape = input_shape_dict['audio']\n",
    "    weight_decay = 0.005\n",
    "\n",
    "    # Video 3D Conv layers\n",
    "    video_input = Input(video_input_shape)\n",
    "    x = Conv3D(8, (3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(video_input)\n",
    "    x = MaxPool3D((2, 2, 2), strides=(2, 2, 2), padding='same')(x)\n",
    "    video_output = Flatten()(x)\n",
    "\n",
    "    # Audio 2D Conv layers\n",
    "    audio_input = Input(audio_input_shape)\n",
    "    x = expand_dims(audio_input)    # add channel dim\n",
    "    x = Conv2D(4, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPool2D((2, 2), strides=(2, 2), padding='same')(x)\n",
    "    audio_output = Flatten()(x)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    fc_input = concatenate([video_output, audio_output])\n",
    "    x = Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(fc_input)\n",
    "    #     x = Dropout(0.2)(x)\n",
    "    fc_output = Dense(1, activation='sigmoid', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    model = Model(inputs=[video_input, audio_input], outputs=fc_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40, 130)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 6, 64, 64, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 40, 130, 1)] 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 6, 64, 64, 8) 656         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 40, 130, 4)   40          tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 3, 32, 32, 8) 0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 20, 65, 4)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 24576)        0           max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5200)         0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 29776)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           476432      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            17          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 477,145\n",
      "Trainable params: 477,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape_dict)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at 20200818-133955\n",
      "optimizer: {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "epochs: 20\n",
      "batch size: 256\n",
      "class weights: (1, 8)\n",
      "normalized class weights: [0.61485043 4.91880342]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66305eddb9b4a948a189648a6cd74b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train 1/20', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56a61379c134a5aac4817a9eea26e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation 1/20', max=15.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model saved to checkpoints\\ckpt-20200818-133955-0001-0.3739.h5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8261bcf4f142719177aa3d6928cdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train 2/20', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e8e9ffba71482a901c40fb90f23ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation 2/20', max=15.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model saved to checkpoints\\ckpt-20200818-133955-0002-0.4239.h5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcff40f266c4966b352637cd46ad030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train 3/20', max=47.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train stopped\n",
      "\n",
      "Top5 models\n",
      "           loss  accuracy  precision    recall   f1score                        checkpoint\n",
      "epoch                                                                                     \n",
      "2      0.413656  0.883421   0.341719  0.558219  0.423927  ckpt-20200818-133955-0002-0.4239\n",
      "1      0.516221  0.853684   0.278524  0.568493  0.373874  ckpt-20200818-133955-0001-0.3739\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 학습 시작\n",
    "trainer = Trainer(model, data_loader, ckpt_dir)\n",
    "trainer.train(Adam(learning_rate), epochs, batch_size, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  가중치 복원\n",
    "모델이 선언되어 있을 때 저장된 가중치를 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'ckpt-20200818-133955-0002-0.4239'\n",
    "model.load_weights(os.path.join(ckpt_dir, checkpoint_name + '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2748adcd3d4c1dbb3a545e12a4c147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=15.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 0.3062, accuracy: 0.8558, precision: 0.4003, recall: 0.6708, f1score: 0.5014\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1score = trainer.test(batch_size)\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1score: {f1score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data count: 3711\n",
      "true_1, pred_1: (401, 672)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2907  403]\n",
      " [ 132  269]]\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      3310\n",
      "           1       0.40      0.67      0.50       401\n",
      "\n",
      "    accuracy                           0.86      3711\n",
      "   macro avg       0.68      0.77      0.71      3711\n",
      "weighted avg       0.90      0.86      0.87      3711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true, y_pred = trainer.test_prediction(batch_size)\n",
    "\n",
    "print(f'test data count: {len(y_true)}')\n",
    "print(f'true_1, pred_1: {y_true.sum(), y_pred.sum()}')\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print()\n",
    "print('Report:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 모든 정보를 온전하게 저장 / 복원\n",
    "모델의 가중치 뿐만아니라 모든 레이어 구성 정보를 저장하여 추후 모델 선언부가 없어도 불러와서 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'ckpt-20200818-124333-0011-0.3412'\n",
    "model_name = checkpoint_name + '_model'\n",
    "model_path = os.path.join(ckpt_dir, model_name + '.h5')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'ckpt-20200818-124333-0011-0.3412'\n",
    "model_name = checkpoint_name + '_model'\n",
    "model_path = os.path.join(ckpt_dir, model_name + '.h5')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_restored = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "trainer = Trainer(model_restored, data_loader, ckpt_dir)\n",
    "\n",
    "loss, accuracy, precision, recall, f1score = trainer.test(batch_size)\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1score: {f1score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
