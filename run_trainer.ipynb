{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Summarizer 모델 학습/평가 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r'E:\\Work\\YasuoNet\\data\\dataset14_sl3_vsr2_vw64_vh64_asr22050_mfcc'\n",
    "ckpt_dir = 'checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "\n",
    "# for basic model\n",
    "# data_loader = DataLoader(dataset_dir, x_includes=['video', 'audio'])\n",
    "# for sequence model\n",
    "data_loader = DataLoader(dataset_dir, x_includes=['video', 'audio'], x_expand=2) # 앞 2개, 뒤 2개 segment 포함\n",
    "\n",
    "data_config = data_loader.get_metadata()['config']\n",
    "input_shape_dict = data_loader.get_metadata()['data_shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "class_weights = (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Conv3D, Conv2D, Input, MaxPool3D, MaxPool2D, Flatten, concatenate\n",
    "from tensorflow.keras.layers import TimeDistributed, LSTM\n",
    "from tensorflow.keras.backend import expand_dims\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_basic_model(input_shape_dict):\n",
    "    video_input_shape = input_shape_dict['video']\n",
    "    audio_input_shape = input_shape_dict['audio']\n",
    "    weight_decay = 0.005\n",
    "\n",
    "    # Video 3D Conv layers\n",
    "    video_input = Input(video_input_shape)\n",
    "    x = video_input\n",
    "    x = Conv3D(8, (3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPool3D((2, 2, 2), strides=(2, 2, 2), padding='same')(x)\n",
    "    video_output = Flatten()(x)\n",
    "\n",
    "    # Audio 2D Conv layers\n",
    "    audio_input = Input(audio_input_shape)\n",
    "    x = expand_dims(audio_input)    # add channel dim\n",
    "    x = Conv2D(4, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPool2D((2, 2), strides=(2, 2), padding='same')(x)\n",
    "    audio_output = Flatten()(x)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    x = concatenate([video_output, audio_output])\n",
    "    x = Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = Dropout(0.2)(x)\n",
    "    fc_output = Dense(1, activation='sigmoid', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    model = Model(inputs=[video_input, audio_input], outputs=fc_output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_sequence_model(input_shape_dict):\n",
    "    video_input_shape = [None,] + input_shape_dict['video']\n",
    "    audio_input_shape = [None,] + input_shape_dict['audio']\n",
    "    weight_decay = 0.005\n",
    "\n",
    "    # Video 3D Conv layers\n",
    "    video_input = Input(video_input_shape)\n",
    "    x = video_input\n",
    "    x = TimeDistributed(Conv3D(8, (3, 3, 3), strides=(1, 1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay)))(x)\n",
    "    x = TimeDistributed(MaxPool3D((2, 2, 2), strides=(2, 2, 2), padding='same'))(x)\n",
    "    video_output = TimeDistributed(Flatten())(x)\n",
    "    print(x.shape, video_output.shape)\n",
    "    \n",
    "    # Audio 2D Conv layers\n",
    "    audio_input = Input(audio_input_shape)\n",
    "    x = expand_dims(audio_input)    # add channel dim\n",
    "    x = TimeDistributed(Conv2D(4, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay)))(x)\n",
    "    x = TimeDistributed(MaxPool2D((2, 2), strides=(2, 2), padding='same'))(x)\n",
    "    audio_output = TimeDistributed(Flatten())(x)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = concatenate([video_output, audio_output])\n",
    "    print(x.shape)\n",
    "    x = LSTM(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    # Fully-connected layers\n",
    "    x = Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "    #     x = Dropout(0.2)(x)\n",
    "    fc_output = Dense(1, activation='sigmoid', kernel_initializer='he_uniform', kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    model = Model(inputs=[video_input, audio_input], outputs=fc_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 3, 32, 32, 8) (None, None, 24576)\n",
      "(None, None, 29776)\n",
      "(None, 16)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 40, 13 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, 6, 64, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, None, 40, 13 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, None, 6, 64,  656         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, None, 40, 130 40          tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, None, 3, 32,  0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, None, 20, 65, 0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, None, 24576)  0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, None, 5200)   0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 29776)  0           time_distributed_8[0][0]         \n",
      "                                                                 time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           1906752     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           272         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            17          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,907,737\n",
      "Trainable params: 1,907,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for basic model\n",
    "# model = build_basic_model(input_shape_dict)\n",
    "# for sequence model\n",
    "model = build_sequence_model(input_shape_dict)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at 20200820-224243\n",
      "optimizer: {'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "epochs: 200\n",
      "batch size: 256\n",
      "class weights: (1, 1)\n",
      "normalized class weights: [1. 1.]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train 1/200', max=47.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7067966461181641\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 학습 시작\n",
    "trainer = Trainer(model, data_loader, ckpt_dir)\n",
    "trainer.train(Adam(learning_rate), epochs, batch_size, class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  가중치 복원\n",
    "모델이 선언되어 있을 때 저장된 가중치를 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'ckpt-20200819-221154-0056-0.4570'\n",
    "model.load_weights(os.path.join(ckpt_dir, checkpoint_name + '.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=15.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 0.1226, accuracy: 0.9076, precision: 0.5662, recall: 0.6185, f1score: 0.5912\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, precision, recall, f1score = trainer.test(batch_size)\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1score: {f1score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data count: 3711\n",
      "true_1, pred_1: (401, 438)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3120  190]\n",
      " [ 153  248]]\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      3310\n",
      "           1       0.57      0.62      0.59       401\n",
      "\n",
      "    accuracy                           0.91      3711\n",
      "   macro avg       0.76      0.78      0.77      3711\n",
      "weighted avg       0.91      0.91      0.91      3711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true, y_pred = trainer.test_prediction(batch_size)\n",
    "\n",
    "print(f'test data count: {len(y_true)}')\n",
    "print(f'true_1, pred_1: {y_true.sum(), y_pred.sum()}')\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print()\n",
    "print('Report:')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 모든 정보를 온전하게 저장 / 복원\n",
    "모델의 가중치 뿐만아니라 모든 레이어 구성 정보를 저장하여 추후 모델 선언부가 없어도 불러와서 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'ckpt-20200818-124333-0011-0.3412'\n",
    "model_name = checkpoint_name + '_model'\n",
    "model_path = os.path.join(ckpt_dir, model_name + '.h5')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints\\ckpt-20200818-124333-0011-0.3412_model.h5\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name = 'ckpt-20200818-124333-0011-0.3412'\n",
    "model_name = checkpoint_name + '_model'\n",
    "model_path = os.path.join(ckpt_dir, model_name + '.h5')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_restored = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 40, 130)]         0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens (None, 40, 130, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 40, 130, 4)        40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 20, 65, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                83216     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 83,273\n",
      "Trainable params: 83,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a99fd35dab141ca8c5d759e28ae8e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test', max=15.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 0.2698, accuracy: 0.8416, precision: 0.3518, recall: 0.5536, f1score: 0.4302\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "trainer = Trainer(model_restored, data_loader, ckpt_dir)\n",
    "\n",
    "loss, accuracy, precision, recall, f1score = trainer.test(batch_size)\n",
    "print(f'loss: {loss:.4f}, accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, f1score: {f1score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}